#pragma once

#include <atomic>
#include <functional>
#include <memory>

#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_core/juce_core.h>
#include <juce_gui_basics/juce_gui_basics.h>
#include <juce_gui_extra/juce_gui_extra.h>

#include "../Config.h"
#include "../asr/ASREngine.h"
#include "../asr/OnnxPythonEngine.h"
#include "../asr/ASROptions.h"
#include "../asr/ASRThreadPoolJob.h"
#include "../asr/WhisperLanguages.h"
#include "../plugin/ReaSpeechLiteAudioProcessorImpl.h"
#include "../reaper/ReaperProxy.h"
#include "../types/MarkerType.h"
#include "../utils/AbortHandler.h"
#include "../utils/SafeUTF8.h"

class NativeFunctions : public OptionsBuilder<juce::WebBrowserComponent::Options>
{
public:
    NativeFunctions (
        juce::ARAEditorView& editorViewIn,
        ReaSpeechLiteAudioProcessorImpl& audioProcessorIn
    ) : editorView (editorViewIn),
        audioProcessor (audioProcessorIn)
    {
        asrEngine = std::make_unique<ASREngine> (Config::getModelsDir());
    }

    // Timeout in milliseconds for aborting transcription jobs
    static constexpr int abortTimeout = 5000;

    juce::WebBrowserComponent::Options buildOptions (const juce::WebBrowserComponent::Options& initialOptions)
    {
        auto bindFn = [this] (auto memberFn)
        {
            return [this, memberFn] (const auto& args, const auto& complete)
            {
                (this->*memberFn) (args, complete);
            };
        };

        return initialOptions
            .withNativeFunction ("abortTranscription", bindFn (&NativeFunctions::abortTranscription))
            .withNativeFunction ("canCreateMarkers", bindFn (&NativeFunctions::canCreateMarkers))
            .withNativeFunction ("createMarkers", bindFn (&NativeFunctions::createMarkers))
            .withNativeFunction ("getAudioSources", bindFn (&NativeFunctions::getAudioSources))
            .withNativeFunction ("getAudioSourceTranscript", bindFn (&NativeFunctions::getAudioSourceTranscript))
            .withNativeFunction ("getModels", bindFn (&NativeFunctions::getModels))
            .withNativeFunction ("getPlayHeadState", bindFn (&NativeFunctions::getPlayHeadState))
            .withNativeFunction ("getProcessingTime", bindFn (&NativeFunctions::getProcessingTime))
            .withNativeFunction ("getRegionSequences", bindFn (&NativeFunctions::getRegionSequences))
            .withNativeFunction ("getTranscriptionStatus", bindFn (&NativeFunctions::getTranscriptionStatus))
            .withNativeFunction ("getWhisperLanguages", bindFn (&NativeFunctions::getWhisperLanguages))
            .withNativeFunction ("insertAudioAtCursor", bindFn (&NativeFunctions::insertAudioAtCursor))
            .withNativeFunction ("play", bindFn (&NativeFunctions::play))
            .withNativeFunction ("stop", bindFn (&NativeFunctions::stop))
            .withNativeFunction ("saveFile", bindFn (&NativeFunctions::saveFile))
            .withNativeFunction ("setAudioSourceTranscript", bindFn (&NativeFunctions::setAudioSourceTranscript))
            .withNativeFunction ("setDebugMode", bindFn (&NativeFunctions::setDebugMode))
            .withNativeFunction ("setPlaybackPosition", bindFn (&NativeFunctions::setPlaybackPosition))
            .withNativeFunction ("setWebState", bindFn (&NativeFunctions::setWebState))
            .withNativeFunction ("transcribeAudioSource", bindFn (&NativeFunctions::transcribeAudioSource));
    }

    void abortTranscription (const juce::var&, std::function<void (const juce::var&)> complete)
    {
        threadPool.removeAllJobs (true, 0); // Non-blocking call to initiate job removal
        new AbortHandler (threadPool, complete, abortTimeout);
    }

    void canCreateMarkers (const juce::var&, std::function<void (const juce::var&)> complete)
    {
        if (rpr.hasAddProjectMarker2)
            complete (juce::var (true));
        else
            complete (juce::var (false));
    }

    void createMarkers (const juce::var& args, std::function<void (const juce::var&)> complete)
    {
        if (! args.isArray() || args.size() < 2 || ! args[0].isArray() || ! args[1].isString())
        {
            complete (makeError ("Invalid arguments"));
            return;
        }

        const auto markers = args[0].getArray();

        const auto markerTypeOpt = MarkerType::fromString (args[1].toString().toStdString());
        if (! markerTypeOpt)
        {
            complete (makeError ("Invalid marker type"));
            return;
        }
        const auto markerType = *markerTypeOpt;

        if (! rpr.hasAddProjectMarker2)
        {
            complete (makeError ("Function not available"));
            return;
        }

        withReaperUndo ("Create " + MarkerType::toString (markerType) + " from transcript", [&] {
            try
            {
                if (markerType == MarkerType::notes)
                    addReaperNotesTrack (markers);
                else if (markerType == MarkerType::takemarkers)
                    addReaperTakeMarkers (markers);
                else
                    addReaperMarkers (markers, markerType);
            }
            catch (const ReaperProxy::Missing& e)
            {
                DBG ("Missing REAPER API function: " + juce::String (e.what()));
            }
        });

        complete (juce::var());
    }

    void getAudioSources (const juce::var&, std::function<void (const juce::var&)> complete)
    {
        if (auto* document = getDocument())
        {
            juce::Array<juce::var> audioSources;
            for (const auto& as : document->getAudioSources<ReaSpeechLiteAudioSource>())
            {
                juce::DynamicObject::Ptr audioSource = new juce::DynamicObject();
                audioSource->setProperty ("name", SafeUTF8::encode (as->getName()));
                audioSource->setProperty ("persistentID", juce::String (as->getPersistentID()));
                audioSource->setProperty ("sampleRate", as->getSampleRate());
                audioSource->setProperty ("sampleCount", (juce::int64) as->getSampleCount());
                audioSource->setProperty ("duration", as->getDuration());
                audioSource->setProperty ("channelCount", as->getChannelCount());
                audioSource->setProperty ("merits64BitSamples", as->merits64BitSamples());
                audioSource->setProperty ("filePath", as->getFilePath());
                audioSources.add (audioSource.get());
            }
            complete (juce::var (audioSources));
            return;
        }
        complete (makeError ("Document not found"));
    }

    void getAudioSourceTranscript (const juce::var& args, std::function<void (const juce::var&)> complete)
    {
        if (! args.isArray() || args.size() < 1 || ! args[0].isString())
        {
            complete (makeError ("Invalid arguments"));
            return;
        }

        const auto audioSourceID = args[0].toString();
        if (auto* document = getDocument())
        {
            const auto& audioSources = document->getAudioSources<ReaSpeechLiteAudioSource>();
            for (const auto& audioSource : audioSources)
            {
                if (audioSource->getPersistentID() == audioSourceID)
                {
                    complete (audioSource->getTranscript());
                    return;
                }
            }
            complete (makeError ("Audio source not found"));
            return;
        }
        complete (makeError ("Document not found"));
    }

    void getModels (const juce::var&, std::function<void (const juce::var&)> complete)
    {
        juce::Array<juce::var> models;
        for (const auto& model : Config::models)
        {
            juce::DynamicObject::Ptr modelObj = new juce::DynamicObject();
            modelObj->setProperty ("name", juce::String(model.first));
            modelObj->setProperty ("label", juce::String(model.second));
            models.add (modelObj.get());
        }
        complete (juce::var (models));
    }

    void getPlayHeadState (const juce::var&, std::function<void (const juce::var&)> complete)
    {
        auto playHeadStateObj = audioProcessor.playHeadState.toDynamicObject();
        complete (juce::var (playHeadStateObj.get()));
    }

    void getRegionSequences (const juce::var&, std::function<void (const juce::var&)> complete)
    {
        if (auto* document = getDocument())
        {
            juce::Array<juce::var> regionSequences;
            for (const auto& rs : document->getRegionSequences())
            {
                juce::DynamicObject::Ptr regionSequence = new juce::DynamicObject();
                regionSequence->setProperty ("name", SafeUTF8::encode (rs->getName()));
                regionSequence->setProperty ("orderIndex", rs->getOrderIndex());

                juce::Array<juce::var> playbackRegions;
                for (const auto& pr : rs->getPlaybackRegions())
                {
                    juce::DynamicObject::Ptr playbackRegion = new juce::DynamicObject();
                    playbackRegion->setProperty ("name", SafeUTF8::encode (pr->getName()));
                    playbackRegion->setProperty ("playbackStart", pr->getStartInPlaybackTime());
                    playbackRegion->setProperty ("playbackEnd", pr->getEndInPlaybackTime());
                    playbackRegion->setProperty ("modificationStart", pr->getStartInAudioModificationTime());
                    playbackRegion->setProperty ("modificationEnd", pr->getEndInAudioModificationTime());
                    auto* audioSource = pr->getAudioModification()->getAudioSource();
                    playbackRegion->setProperty ("audioSourcePersistentID", juce::String (audioSource->getPersistentID()));
                    playbackRegions.add (playbackRegion.get());
                }
                regionSequence->setProperty ("playbackRegions", playbackRegions);

                regionSequences.add (regionSequence.get());
            }

            complete (juce::var (regionSequences));
            return;
        }
        complete (makeError ("Document not found"));
    }

    void getTranscriptionStatus (const juce::var&, std::function<void (const juce::var&)> complete)
    {
        juce::String status;
        int progress = 0;
        switch (asrStatus.load())
        {
            case ASRThreadPoolJobStatus::exporting:
                status = "Exporting";
                break;
            case ASRThreadPoolJobStatus::downloadingModel:
                status = "Downloading";
                if (asrEngine != nullptr)
                    progress = asrEngine->getProgress();
                if (onnxEngine != nullptr)
                    progress = onnxEngine->getProgress();
                break;
            case ASRThreadPoolJobStatus::loadingModel:
                status = "Loading Model";
                break;
            case ASRThreadPoolJobStatus::transcribing:
                status = "Transcribing";
                if (asrEngine != nullptr)
                    progress = asrEngine->getProgress();
                if (onnxEngine != nullptr)
                    progress = onnxEngine->getProgress();
                break;
            case ASRThreadPoolJobStatus::ready:
            case ASRThreadPoolJobStatus::aborted:
            case ASRThreadPoolJobStatus::finished:
            case ASRThreadPoolJobStatus::failed:
                break;
        }
        juce::DynamicObject::Ptr result = new juce::DynamicObject();
        result->setProperty ("status", status);
        result->setProperty ("progress", progress);
        complete (juce::var (result.get()));
    }

    void getWhisperLanguages (const juce::var&, std::function<void (const juce::var&)> complete)
    {
        complete (juce::var (WhisperLanguages::get()));
    }

    void play (const juce::var&, std::function<void (const juce::var&)> complete)
    {
        if (auto* playbackController = getPlaybackController())
        {
            playbackController->requestStartPlayback();
            complete (juce::var());
            return;
        }
        complete (makeError ("Playback controller not found"));
    }

    void stop (const juce::var&, std::function<void (const juce::var&)> complete)
    {
        if (auto* playbackController = getPlaybackController())
        {
            playbackController->requestStopPlayback();
            complete (juce::var());
            return;
        }
        complete (makeError ("Playback controller not found"));
    }

    void saveFile (const juce::var& args, std::function<void (const juce::var&)> complete)
    {
        if (! args.isArray() || args.size() < 4 || ! args[0].isString() || ! args[1].isString() || ! args[2].isString() || ! args[3].isString())
        {
            complete (makeError ("Invalid arguments"));
            return;
        }

        const auto title = args[0].toString();
        const auto initialFilename = args[1].toString();
        const auto patterns = args[2].toString();
        const auto content = args[3].toString();

        const auto initialFile = juce::File::getSpecialLocation (juce::File::userDocumentsDirectory)
            .getChildFile (initialFilename);

        const auto flags = juce::FileBrowserComponent::saveMode
            | juce::FileBrowserComponent::canSelectFiles
            | juce::FileBrowserComponent::warnAboutOverwriting;

        fileChooser = std::make_unique<juce::FileChooser> (title, initialFile, patterns);
        fileChooser->launchAsync (flags, [this, content, complete] (const juce::FileChooser& chooser)
        {
            const auto file = chooser.getResult();
            if (file != juce::File())
            {
                if (file.replaceWithText (content, false))
                {
                    juce::DynamicObject::Ptr result = new juce::DynamicObject();
                    result->setProperty ("filePath", file.getFullPathName());
                    complete (juce::var (result.get()));
                    return;
                }
                complete (makeError ("Failed to save file"));
                return;
            }
            juce::DynamicObject::Ptr result = new juce::DynamicObject();
            result->setProperty ("filePath", "");
            complete (juce::var (result.get()));
        });
    }

    void setAudioSourceTranscript (const juce::var& args, std::function<void (const juce::var&)> complete)
    {
        if (! args.isArray() || args.size() < 2 || ! args[0].isString() || ! args[1].isObject())
        {
            complete (makeError ("Invalid arguments"));
            return;
        }

        const auto audioSourceID = args[0].toString();
        const auto transcript = args[1].getDynamicObject();

        if (auto* document = getDocument())
        {
            const auto& audioSources = document->getAudioSources<ReaSpeechLiteAudioSource>();
            for (const auto& audioSource : audioSources)
            {
                if (audioSource->getPersistentID() == audioSourceID)
                {
                    audioSource->setTranscript (transcript);
                    complete (juce::var());
                    return;
                }
            }
            complete (makeError ("Audio source not found"));
            return;
        }
        complete (makeError ("Document not found"));
    }

    void setPlaybackPosition (const juce::var& args, std::function<void (const juce::var&)> complete)
    {
        if (! args.isArray() || args.size() < 1)
        {
            complete (makeError ("Invalid arguments"));
            return;
        }

        if (auto* playbackController = getPlaybackController())
        {
            const double position = args[0];
            playbackController->requestSetPlaybackPosition (position);
            complete (juce::var());
            return;
        }
        complete (makeError ("Playback controller not found"));
    }

    void setWebState (const juce::var& args, std::function<void (const juce::var&)> complete)
    {
        if (! args.isArray() || args.size() < 1 || ! args[0].isString())
        {
            complete (makeError ("Invalid arguments"));
            return;
        }

        audioProcessor.state.setProperty ("webState", args[0], nullptr);
        complete (juce::var());
    }

    void transcribeAudioSource (const juce::var& args, std::function<void (const juce::var&)> complete)
    {
        if (! args.isArray() || args.size() < 1)
        {
            complete (makeError ("Invalid arguments"));
            return;
        }

        if (asrEngine == nullptr)
        {
            complete (makeError ("ASR engine not initialized"));
            return;
        }

        std::unique_ptr<ASROptions> options = std::make_unique<ASROptions>();
        if (args.size() > 1)
        {
            const auto optionsObj = args[1].getDynamicObject();
            if (optionsObj != nullptr)
            {
                if (optionsObj->hasProperty ("modelName"))
                    options->modelName = optionsObj->getProperty ("modelName");
                if (optionsObj->hasProperty ("language"))
                    options->language = optionsObj->getProperty ("language");
                if (optionsObj->hasProperty ("translate"))
                    options->translate = optionsObj->getProperty ("translate");
            }
        }

        const auto audioSourcePersistentID = args[0].toString();
        if (auto* audioSource = getAudioSourceByPersistentID (audioSourcePersistentID))
        {
            // Determine which engine to use based on model name
            bool useOnnx = Config::isOnnxModel (options->modelName.toStdString());

            if (useOnnx && onnxEngine == nullptr)
            {
                onnxEngine = std::make_unique<OnnxPythonEngine> (Config::getModelsDir());
            }

            juce::ThreadPoolJob* job = nullptr;

            auto statusCallback = [this] (ASRThreadPoolJobStatus status) {
                asrStatus = status;
            };

            auto completionCallback = [this, complete] (const ASRThreadPoolJobResult& result) {
                if (result.isError)
                    complete (makeError (result.errorMessage));
                else
                {
                    juce::DynamicObject::Ptr obj = new juce::DynamicObject();
                    juce::Array<juce::var> segments;
                    for (const auto& segment : result.segments)
                        segments.add (segment.toDynamicObject(false).get());
                    obj->setProperty ("segments", segments);
                    complete (juce::var (obj.get()));
                }
            };

            // Look up file path if needed (for REAPER integration)
            auto* rsAudioSource = dynamic_cast<ReaSpeechLiteAudioSource*>(audioSource);
            if (rsAudioSource && rsAudioSource->getFilePath().isEmpty())
            {
                juce::String audioSourceName = SafeUTF8::encode (audioSource->getName());
                juce::String audioFilePath;

                if (rpr.hasCountMediaItems && rpr.hasGetMediaItem && rpr.hasGetActiveTake &&
                    rpr.hasGetMediaItemTake_Source && rpr.hasGetMediaSourceFileName)
                {
                    int numItems = rpr.CountMediaItems (ReaperProxy::activeProject);
                    for (int i = 0; i < numItems; ++i)
                    {
                        auto* item = rpr.GetMediaItem (ReaperProxy::activeProject, i);
                        auto* take = rpr.GetActiveTake (item);
                        if (take != nullptr)
                        {
                            auto* source = rpr.GetMediaItemTake_Source (take);
                            if (source != nullptr)
                            {
                                char filenamebuf[4096];
                                rpr.GetMediaSourceFileName (source, filenamebuf, sizeof(filenamebuf));
                                juce::String filename (filenamebuf);
                                juce::String filenameWithoutExt = juce::File(filename).getFileNameWithoutExtension();
                                juce::String audioSourceNameWithoutExt = audioSourceName.upToLastOccurrenceOf(".", false, false);

                                if (filename.isNotEmpty() && filenameWithoutExt == audioSourceNameWithoutExt)
                                {
                                    audioFilePath = filename;
                                    break;
                                }
                            }
                        }
                    }
                }

                rsAudioSource->setFilePath (audioFilePath);
            }

            if (useOnnx)
            {
                job = new ASRThreadPoolJob<OnnxPythonEngine> (
                    *onnxEngine,
                    audioSource,
                    std::move(options),
                    statusCallback,
                    completionCallback
                );
            }
            else
            {
                job = new ASRThreadPoolJob<ASREngine> (
                    *asrEngine,
                    audioSource,
                    std::move(options),
                    statusCallback,
                    completionCallback
                );
            }

            threadPool.addJob (job, true);
            return;
        }
        complete (makeError ("Audio source not found"));
    }

    void insertAudioAtCursor (const juce::var& args, std::function<void (const juce::var&)> complete)
    {
        if (!args.isArray() || args.size() < 3 || !args[2].isString())
        {
            complete (makeError ("Invalid arguments"));
            return;
        }

        const double startTime = args[0];
        const double endTime = args[1];
        const auto audioFilePath = args[2].toString();
        const double itemLength = endTime - startTime;

        if (audioFilePath.isEmpty())
        {
            complete (makeError ("Audio file path is empty"));
            return;
        }

        juce::File sourceFile (audioFilePath);
        if (!sourceFile.existsAsFile())
        {
            complete (makeError ("Audio file not found: " + audioFilePath));
            return;
        }

        ReaperProxy::MediaTrack* track = nullptr;
        if (rpr.hasCountSelectedTracks && rpr.hasGetSelectedTrack)
        {
            int numSelectedTracks = rpr.CountSelectedTracks (ReaperProxy::activeProject);
            if (numSelectedTracks > 0)
                track = rpr.GetSelectedTrack (ReaperProxy::activeProject, 0);
        }

        if (track == nullptr && rpr.hasGetLastTouchedTrack)
            track = rpr.GetLastTouchedTrack();

        if (track == nullptr)
        {
            complete (makeError ("No track selected or available"));
            return;
        }

        const auto cursorPos = rpr.GetCursorPositionEx (ReaperProxy::activeProject);

        withReaperUndo ("Insert audio segment", [&] {
            try
            {
                auto* item = rpr.AddMediaItemToTrack (track);
                rpr.SetMediaItemPosition (item, cursorPos, true);
                rpr.SetMediaItemLength (item, itemLength, true);

                auto* take = rpr.AddTakeToMediaItem (item);
                auto* pcmSource = rpr.PCM_Source_CreateFromFile (audioFilePath.toRawUTF8());
                rpr.SetMediaItemTake_Source (take, pcmSource);

                if (rpr.hasSetMediaItemTakeInfo_Value)
                    rpr.SetMediaItemTakeInfo_Value (take, "D_STARTOFFS", startTime);
            }
            catch (const ReaperProxy::Missing& e)
            {
                DBG ("Missing REAPER API function: " + juce::String (e.what()));
            }
        });

        complete (juce::var());
    }

    void setDebugMode (const juce::var& args, std::function<void (const juce::var&)> complete)
    {
        if (!args.isBool())
        {
            complete (makeError ("Invalid arguments"));
            return;
        }

        debugMode.store (args);
        complete (juce::var());
    }

    void getProcessingTime (const juce::var&, std::function<void (const juce::var&)> complete)
    {
        if (asrEngine != nullptr)
        {
            complete (juce::var (asrEngine->getProcessingTime()));
            return;
        }
        if (onnxEngine != nullptr)
        {
            complete (juce::var (onnxEngine->getProcessingTime()));
            return;
        }
        complete (juce::var (0.0));
    }

private:
    ReaSpeechLiteDocumentController* getDocumentController()
    {
        return ReaSpeechLiteDocumentController::get (editorView);
    }

    ARA::PlugIn::HostPlaybackController* getPlaybackController()
    {
        if (auto* documentController = getDocumentController())
            return documentController->getPlaybackController();
        return nullptr;
    }

    juce::ARADocument* getDocument()
    {
        if (auto* documentController = getDocumentController())
            return documentController->getDocument();
        return nullptr;
    }

    juce::ARAAudioSource* getAudioSourceByPersistentID (const juce::String& audioSourcePersistentID)
    {
        if (auto* document = getDocument())
        {
            for (const auto& as : document->getAudioSources())
                if (as->getPersistentID() == audioSourcePersistentID)
                    return as;

        }
        return nullptr;
    }

    juce::var makeError (const juce::String& message)
    {
        juce::DynamicObject::Ptr error = new juce::DynamicObject();
        error->setProperty ("error", message);
        return juce::var (error.get());
    }

    void addReaperMarkers (const juce::Array<juce::var>* markers, const MarkerType::Enum markerType)
    {
        int markerNum = 1;
        for (const auto& markerVar : *markers)
        {
            const auto marker = markerVar.getDynamicObject();
            const auto regions = markerType == MarkerType::regions;
            const auto start = marker->getProperty ("start");
            const auto end = marker->getProperty ("end");
            const auto name = marker->getProperty ("name");

            rpr.AddProjectMarker2 (ReaperProxy::activeProject, regions, start, end, name.toString().toRawUTF8(), markerNum, 0);
            markerNum++;
        }
    }

    void addReaperNotesTrack (const juce::Array<juce::var>* markers, const char* trackName = "Transcript")
    {
        const auto index = 0;
        const auto originalPosition = rpr.GetCursorPositionEx (ReaperProxy::activeProject);

        rpr.InsertTrackInProject (ReaperProxy::activeProject, index, 0);
        const auto track = rpr.GetTrack (ReaperProxy::activeProject, index);
        rpr.SetOnlyTrackSelected (track);
        rpr.GetSetMediaTrackInfo_String (track, "P_NAME", const_cast<char*> (trackName), true);

        for (const auto& markerVar : *markers)
        {
            const auto marker = markerVar.getDynamicObject();
            const auto start = marker->getProperty ("start");
            const auto end = marker->getProperty ("end");
            const auto name = marker->getProperty ("name");

            const auto item = createEmptyReaperItem (start, end);
            setReaperNoteText (item, name.toString());
        }

        rpr.SetEditCurPos2 (ReaperProxy::activeProject, originalPosition, true, true);
    }

    void addReaperTakeMarkers (const juce::Array<juce::var>* markers)
    {
        // Get the last touched track to find relevant media items
        auto* track = rpr.GetLastTouchedTrack();
        if (track == nullptr)
        {
            DBG ("No track selected or touched");
            return;
        }

        // Get all media items in the project
        int numItems = rpr.CountMediaItems (ReaperProxy::activeProject);

        for (const auto& markerVar : *markers)
        {
            const auto marker = markerVar.getDynamicObject();
            double sourcePos = marker->getProperty ("start");
            const auto name = marker->getProperty ("name");
            const auto sourceID = marker->getProperty ("sourceID").toString();

            // Find the media item with the matching audio source
            for (int i = 0; i < numItems; ++i)
            {
                auto* item = rpr.GetMediaItem (ReaperProxy::activeProject, i);

                // Check if item is on the touched track
                double itemTrackNum = rpr.GetMediaItemInfo_Value (item, "P_TRACK");
                if (reinterpret_cast<ReaperProxy::MediaTrack*> (static_cast<intptr_t> (itemTrackNum)) != track)
                    continue;

                // Get the active take from the item
                auto* take = rpr.GetActiveTake (item);
                if (take == nullptr)
                    continue;

                // Get the take's source
                auto* source = rpr.GetMediaItemTake_Source (take);
                if (source == nullptr)
                    continue;

                // Get the source filename
                char filenamebuf[4096];
                rpr.GetMediaSourceFileName (source, filenamebuf, sizeof(filenamebuf));
                juce::String filename (filenamebuf);

                // Match by audio source ID (contained in filename)
                if (filename.contains (sourceID))
                {
                    // Add take marker: idx -1 means insert new marker
                    int result = rpr.SetTakeMarker (take, -1, name.toString().toRawUTF8(), &sourcePos, nullptr);
                    if (result >= 0)
                    {
                        DBG ("Added take marker: " + name.toString() + " at " + juce::String (sourcePos));
                    }
                    break; // Move to next marker after finding matching item
                }
            }
        }
    }

    ReaperProxy::MediaItem* createEmptyReaperItem (const double start, const double end)
    {
        rpr.Main_OnCommandEx(40142, 0, ReaperProxy::activeProject); // Insert empty item
        auto* item = rpr.GetSelectedMediaItem(ReaperProxy::activeProject, 0);
        rpr.SelectAllMediaItems (ReaperProxy::activeProject, false);
        rpr.SetMediaItemPosition (item, start, true);
        rpr.SetMediaItemLength (item, end - start, true);
        return item;
    }

    void setReaperNoteText (ReaperProxy::MediaItem* item, const juce::String& text, bool stretch = false)
    {
        char buffer[4096];
        rpr.GetItemStateChunk (item, buffer, sizeof (buffer), false);
        const auto chunk = juce::String (buffer);

        // This function is currently only used with new items, and the chunk size
        // in that case is currently around 200 bytes. If this changes, the buffer
        // size may need to be increased. The current size is a bit arbitrary.
        auto chunkSize = static_cast<size_t> (chunk.length());
        auto bufferSize = sizeof (buffer);
        jassert (chunkSize < bufferSize - 1);

        juce::String notesChunk;
        notesChunk << "<NOTES\n|" << text.trim() << "\n>\n";
        const juce::String flagsChunk { stretch ? "IMGRESOURCEFLAGS 11\n" : "" };

        const auto newChunk = chunk.replace(">", notesChunk.replace ("%", "%%") + flagsChunk + ">");
        rpr.SetItemStateChunk (item, newChunk.toRawUTF8(), false);
    }

    void withReaperUndo (const juce::String& label, std::function<void()> action)
    {
        if (rpr.hasPreventUIRefresh)
            rpr.PreventUIRefresh(1);

        if (rpr.hasUndo_BeginBlock2)
            rpr.Undo_BeginBlock2(ReaperProxy::activeProject);

        action();

        if (rpr.hasUndo_EndBlock2)
            rpr.Undo_EndBlock2(ReaperProxy::activeProject, label.toRawUTF8(), -1);

        if (rpr.hasPreventUIRefresh)
            rpr.PreventUIRefresh(-1);
    }

    juce::ARAEditorView& editorView;
    ReaSpeechLiteAudioProcessorImpl& audioProcessor;
    ReaperProxy& rpr { audioProcessor.reaperProxy };

    std::unique_ptr<ASREngine> asrEngine;
    std::unique_ptr<OnnxPythonEngine> onnxEngine;
    std::atomic<ASRThreadPoolJobStatus> asrStatus;
    std::atomic<bool> debugMode { false };
    juce::ThreadPool threadPool { 1 };

    std::unique_ptr<juce::FileChooser> fileChooser;
};
